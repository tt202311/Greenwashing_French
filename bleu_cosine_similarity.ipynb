{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU Score"
      ],
      "metadata": {
        "id": "hn7Q7AP8BitH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translated dataset"
      ],
      "metadata": {
        "id": "rVb48_kDBrsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "greenwashing_dataset_path = '/content/Dataset_greenwashing - Sheet1.csv'\n",
        "translated_dataset_path = '/content/translated_claims_validation (1).csv'\n",
        "\n",
        "greenwashing_data = pd.read_csv(greenwashing_dataset_path)\n",
        "translated_data = pd.read_csv(translated_dataset_path)\n",
        "\n",
        "# Extract necessary columns\n",
        "greenwashing_texts = greenwashing_data['Text'].tolist()\n",
        "translated_texts = translated_data['translated_text'].tolist()\n",
        "\n",
        "# Align datasets based on the smallest length\n",
        "min_length = min(len(greenwashing_texts), len(translated_texts))\n",
        "aligned_references = [[text.split()] for text in greenwashing_texts[:min_length]]\n",
        "aligned_candidates = [text.split() for text in translated_texts[:min_length]]\n",
        "\n",
        "# Calculate BLEU score with smoothing\n",
        "smoothing_function = SmoothingFunction().method1\n",
        "bleu_score = corpus_bleu(aligned_references, aligned_candidates, smoothing_function=smoothing_function)\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1AjUWZMBi_W",
        "outputId": "8ac90938-0e1d-4b03-a1a2-346a831f9f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.0011136552591733703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masked dataset"
      ],
      "metadata": {
        "id": "xQ0MBeabBxck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "# Load the masked dataset\n",
        "masked_dataset_path = '/content/masked_training_dataset (3).csv'\n",
        "masked_data = pd.read_csv(masked_dataset_path)\n",
        "\n",
        "# Extract the necessary columns\n",
        "original_texts = masked_data['text'].tolist()  # Original English text\n",
        "masked_texts = masked_data['masked_text'].tolist()  # Masked translated text\n",
        "\n",
        "# Ensure datasets are aligned\n",
        "min_length = min(len(original_texts), len(masked_texts))\n",
        "original_texts = original_texts[:min_length]\n",
        "masked_texts = masked_texts[:min_length]\n",
        "\n",
        "# Prepare the data for BLEU calculation\n",
        "# BLEU expects references as a list of lists of tokens\n",
        "references = [[text.split()] for text in original_texts]\n",
        "candidates = [text.split() for text in masked_texts]\n",
        "\n",
        "# Calculate BLEU score with smoothing\n",
        "smoothing_function = SmoothingFunction().method1\n",
        "bleu_score = corpus_bleu(references, candidates, smoothing_function=smoothing_function)\n",
        "\n",
        "print(f\"BLEU Score (Masked Dataset): {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E_29-GLBbwL",
        "outputId": "44cc4e5d-88d8-47df-fabb-858a51b673d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score (Masked Dataset): 0.003533243146624169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Similarity"
      ],
      "metadata": {
        "id": "zhr0UnS_B_VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **semantic similarity** metric measures how closely the meaning of two pieces of text aligns, regardless of their syntactic or surface-level differences. It focuses on capturing the semantic content (the underlying meaning) rather than direct word-for-word matches.\n",
        "\n",
        "here, we use cosine similarity.\n",
        "\n",
        "Cosine Similarity:\n",
        "*   Measures the cosine of the angle between two vectors in an embedding space.\n",
        "*   Range: [0, 1] (or [-1, 1] in some cases, where negative values indicate dissimilarity).\n",
        "*  Values close to 1 indicate strong semantic similarity."
      ],
      "metadata": {
        "id": "YbkOvi_dBV6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translated dataset"
      ],
      "metadata": {
        "id": "7waF0AUsCE6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load datasets\n",
        "greenwashing_dataset_path = '/content/Dataset_greenwashing - Sheet1.csv'\n",
        "translated_dataset_path = '/content/translated_claims_validation (1).csv'\n",
        "\n",
        "original_data = pd.read_csv(greenwashing_dataset_path)\n",
        "translated_data = pd.read_csv(translated_dataset_path)\n",
        "\n",
        "# Extract the relevant text columns\n",
        "original_texts = original_data['Text'].tolist()\n",
        "translated_texts = translated_data['translated_text'].tolist()\n",
        "\n",
        "# Ensure the datasets are aligned\n",
        "min_length = min(len(original_texts), len(translated_texts))\n",
        "original_texts = original_texts[:min_length]\n",
        "translated_texts = translated_texts[:min_length]\n",
        "\n",
        "# Load a multilingual Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Generate embeddings\n",
        "original_embeddings = model.encode(original_texts, convert_to_tensor=True)\n",
        "translated_embeddings = model.encode(translated_texts, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity for each pair\n",
        "similarities = cosine_similarity(original_embeddings.cpu(), translated_embeddings.cpu())\n",
        "\n",
        "# Calculate the average similarity score\n",
        "average_similarity = np.mean(np.diag(similarities))\n",
        "\n",
        "print(f\"Average Semantic Similarity: {average_similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyKalogf7TRU",
        "outputId": "cda8550d-ef08-4a56-baea-6ab3e1e61d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Semantic Similarity: 0.23899298906326294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masked dataset"
      ],
      "metadata": {
        "id": "qZ9kkC1ACLxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the masked dataset\n",
        "masked_dataset_path = '/content/masked_training_dataset (3).csv'\n",
        "masked_data = pd.read_csv(masked_dataset_path)\n",
        "\n",
        "# Extract the necessary columns\n",
        "original_texts = masked_data['text'].tolist()  # Original English text\n",
        "masked_texts = masked_data['masked_text'].tolist()  # Masked translated text\n",
        "\n",
        "# Ensure datasets are aligned\n",
        "min_length = min(len(original_texts), len(masked_texts))\n",
        "original_texts = original_texts[:min_length]\n",
        "masked_texts = masked_texts[:min_length]\n",
        "\n",
        "# Load a multilingual Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Generate embeddings for the original and masked texts\n",
        "original_embeddings = model.encode(original_texts, convert_to_tensor=True)\n",
        "masked_embeddings = model.encode(masked_texts, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity for each pair\n",
        "masked_similarities = cosine_similarity(original_embeddings.cpu(), masked_embeddings.cpu())\n",
        "\n",
        "# Calculate the average semantic similarity\n",
        "average_masked_similarity = np.mean(np.diag(masked_similarities))\n",
        "\n",
        "print(f\"Average Semantic Similarity (Masked Dataset): {average_masked_similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KXrKFpY-Md5",
        "outputId": "5f9f945a-a183-49da-a00f-64e85174bd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Semantic Similarity (Masked Dataset): 0.8803374171257019\n"
          ]
        }
      ]
    }
  ]
}